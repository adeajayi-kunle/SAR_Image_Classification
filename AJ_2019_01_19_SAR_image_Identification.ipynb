{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "# import classical libraries\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import functions\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.misc import imread\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Prepare the datasets\n",
    "\n",
    "Now, we load the training (70%) and validation (30%) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths to the training and validation datasets\n",
    "database = '/Users/adekunle/Projects/Others/Data_Science/Data_Science_for_Geosciences/Data/'\n",
    "path_train = database + \"training/\"\n",
    "path_validation = database + \"validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class names\n",
    "classes = ['F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O']\n",
    "\n",
    "# initialization\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_validation = []\n",
    "y_validation = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adekunle/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel/__main__.py:8: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/Users/adekunle/anaconda/envs/python36/lib/python3.6/site-packages/ipykernel/__main__.py:16: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "# loop on images\n",
    "for j in range(len(classes)):\n",
    "    path = path_train + classes[j]\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    \n",
    "    # training\n",
    "    for i in range(len(files)):\n",
    "        tmp = imread(path + '/' + files[i])\n",
    "        X_train.append(ravel(tmp[0:450,0:450:,0]))\n",
    "        y_train.append(classes[j])\n",
    "    \n",
    "    # validation\n",
    "    path = path_validation + classes[j]\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    for i in range(len(files)):\n",
    "        tmp = imread(path + '/' + files[i])\n",
    "        X_validation.append(ravel(tmp[0:450,0:450:,0]))\n",
    "        y_validation.append(classes[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to array\n",
    "X_train = asarray(X_train)\n",
    "y_train = asarray(y_train)\n",
    "X_validation = asarray(X_validation)\n",
    "y_validation = asarray(y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Datasets size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape :  (1120, 202500)\n",
      "y_train shape :  (1120,)\n",
      "X_validation shape :  (480, 202500)\n",
      "y_validation shape :  (480,)\n"
     ]
    }
   ],
   "source": [
    "xt_len = len(X_train)\n",
    "xv_len = len(X_validation)\n",
    "print('X_train shape : ',X_train.shape)\n",
    "print('y_train shape : ',y_train.shape)\n",
    "print('X_validation shape : ',X_validation.shape)\n",
    "print('y_validation shape : ',y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â 3 - Multiple Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adekunle/anaconda/envs/python36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# - import models\n",
    "import scipy as sp\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifier list\n",
    "classifiers = [NearestCentroid(),SVC(), KNeighborsClassifier(), QuadraticDiscriminantAnalysis(), \n",
    "               LinearDiscriminantAnalysis(solver=\"lsqr\"),RandomForestClassifier()]\n",
    "names = [\"NC\",\"SVM\", \"KNN\", \"QDA\", \"LDA\",\"RDF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the dictionnary of parameters to optimize\n",
    "param_grids = [dict(shrink_threshold=np.arange(1,10,1)),\n",
    "               dict(kernel=['rbf'], gamma=1.0*sp.arange(1,12,2), C= 1.0*sp.arange(1,12,2),degree=sp.arange(1,10)),\n",
    "               dict(n_neighbors = sp.arange(1,40)), # number of neighbors for KNN\n",
    "               dict(reg_param = sp.linspace(0,0.1,30)), # Regularization parameter for QDA\n",
    "               dict(shrinkage = sp.linspace(0,0.5,30)), # Regularization parameter for LDA\n",
    "               dict(max_depth=np.arange(1,15,1),n_estimators = np.arange(1,100,10)), # Number of depths for  RDF\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# - define function to run multiple model\n",
    "def run_multiple_models(X_train_trans,X_validation_trans):   \n",
    "    # Run all classifiers\n",
    "    global classifier,name,param_grid\n",
    "    global y_train,y_validation\n",
    "    for classifier, name, param_grid in zip(classifiers, names, param_grids):\n",
    "        grid = GridSearchCV(classifier, param_grid=param_grid, cv= 3, n_jobs=-1)\n",
    "        grid.fit(X_train_trans, y_train)\n",
    "\n",
    "        clf = grid.best_estimator_ \n",
    "        clf.fit(X_train_trans,y_train)\n",
    "\n",
    "        y_predict = clf.predict(X_validation_trans)\n",
    "        model_accuracy = \"{:1.2f}\".format(accuracy_score(y_validation,y_predict))\n",
    "        best_param = grid.best_params_\n",
    "        print(\"Accuracy score for {}: {} (best parameters {})\".format(name,model_accuracy,best_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Feature Exraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Principal Component Analysis (PCA) Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transform shape :  (1120, 100)\n",
      "X_validation_transform shape :  (480, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# - combine X_train and X_validation\n",
    "X = np.concatenate((X_train,X_validation),axis=0)\n",
    "# - specify number of components\n",
    "n_components = 100\n",
    "pca = PCA(n_components=n_components)\n",
    "# - transform X datasets\n",
    "Transform_X = pca.fit_transform(X)\n",
    "# - split X into X_train and X_validation\n",
    "X_train_transform = Transform_X[:xt_len,:]\n",
    "X_validation_transform = Transform_X[xt_len:,:]\n",
    "# - print X size\n",
    "print('X_train_transform shape : ',X_train_transform.shape)\n",
    "print('X_validation_transform shape : ',X_validation_transform.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Histogram of Oriented Gradient (HOG) Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_image_hog(X): \n",
    "    '''Compute gradient of the image\n",
    "    and obtain the histogram of the gradients'''\n",
    "    n = 450 # shape of the matrix\n",
    "    _X_hog = []\n",
    "    for i in range(len(X)):#iterate over all image vectors\n",
    "        X_reshape = reshape(X[i,:],[n,n])\n",
    "        image_grad = np.gradient(X_reshape)\n",
    "        total_grad = np.sqrt(image_grad[0]**2 + image_grad[1]**2)\n",
    "        bin_count,bin_scale = np.histogram(ravel(total_grad),bins=25,range=(0,250))\n",
    "        _X_hog.append(bin_count)\n",
    "    X_hog = np.array(_X_hog)\n",
    "    return X_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hog shape :  (1120, 25)\n",
      "X_validation_hog shape :  (480, 25)\n"
     ]
    }
   ],
   "source": [
    "X_train_hog = compute_image_hog(X_train)\n",
    "X_validation_hog = compute_image_hog(X_validation)\n",
    "print('X_train_hog shape : ',X_train_hog.shape)\n",
    "print('X_validation_hog shape : ',X_validation_hog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Histogram of the Image pixels (HOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_stats_1D(x):\n",
    "    '''Compute statistics for the 1-D array'''\n",
    "    mean = int(sp.mean(x))\n",
    "    median = int(sp.median(x))\n",
    "    skew = int(sp.stats.skew(x,bias=True))\n",
    "    std = int(sp.std(x))\n",
    "    x_stat = np.array([mean,median,skew,std])\n",
    "    return x_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_pixel_hist(X): \n",
    "    n = 450 # shape of the matrix\n",
    "    _X_hist = []\n",
    "    for i in range(len(X)):#iterate over all image vectors\n",
    "        bin_count,bin_scale = np.histogram(X[i,:],bins=20,range=(0,255))\n",
    "        x_stat = compute_stats_1D(X[i,:]) \n",
    "        X_f = np.concatenate((bin_count,x_stat),axis=0)\n",
    "        _X_hist.append(X_f )\n",
    "    X_hist = np.array(_X_hist)\n",
    "    return X_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_pxl shape :  (1120, 24)\n",
      "X_validation_pxl shape :  (480, 24)\n"
     ]
    }
   ],
   "source": [
    "X_train_pxl_hist = compute_pixel_hist(X_train)\n",
    "X_validation_pxl_hist = compute_pixel_hist(X_validation)\n",
    "print('X_train_pxl shape : ',X_train_pxl_hist.shape)\n",
    "print('X_validation_pxl shape : ',X_validation_pxl_hist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for NC: 0.25 (best parameters {'shrink_threshold': 2})\n",
      "Accuracy score for SVM: 0.10 (best parameters {'C': 1.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'rbf'})\n",
      "Accuracy score for KNN: 0.34 (best parameters {'n_neighbors': 1})\n",
      "Accuracy score for QDA: 0.18 (best parameters {'reg_param': 0.003448275862068966})\n",
      "Accuracy score for LDA: 0.36 (best parameters {'shrinkage': 0.3620689655172414})\n",
      "Accuracy score for RDF: 0.48 (best parameters {'max_depth': 13, 'n_estimators': 81})\n"
     ]
    }
   ],
   "source": [
    "# - Run result for PCA\n",
    "run_multiple_models(X_train_transform,X_validation_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for NC: 0.33 (best parameters {'shrink_threshold': 1})\n",
      "Accuracy score for SVM: 0.10 (best parameters {'C': 1.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'rbf'})\n",
      "Accuracy score for KNN: 0.42 (best parameters {'n_neighbors': 13})\n",
      "Accuracy score for QDA: 0.45 (best parameters {'reg_param': 0.010344827586206898})\n",
      "Accuracy score for LDA: 0.49 (best parameters {'shrinkage': 0.0})\n",
      "Accuracy score for RDF: 0.46 (best parameters {'max_depth': 11, 'n_estimators': 91})\n"
     ]
    }
   ],
   "source": [
    "# - Run result for HOG\n",
    "run_multiple_models(X_train_hog,X_validation_hog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - HOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for NC: 0.34 (best parameters {'shrink_threshold': 1})\n",
      "Accuracy score for SVM: 0.10 (best parameters {'C': 1.0, 'degree': 1, 'gamma': 1.0, 'kernel': 'rbf'})\n",
      "Accuracy score for KNN: 0.47 (best parameters {'n_neighbors': 13})\n",
      "Accuracy score for QDA: 0.48 (best parameters {'reg_param': 0.01724137931034483})\n",
      "Accuracy score for LDA: 0.39 (best parameters {'shrinkage': 0.017241379310344827})\n",
      "Accuracy score for RDF: 0.55 (best parameters {'max_depth': 13, 'n_estimators': 51})\n"
     ]
    }
   ],
   "source": [
    "# - Run result for pixel histogram\n",
    "run_multiple_models(X_train_pxl_hist,X_validation_pxl_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Tabulate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [{'NC': 0.26, 'SVM': 0.10,'KNN':0.32,'QDA':0.19,'LDA':0.37,'RDF':0.54},\n",
    "        {'NC': 0.34, 'SVM': 0.10,'KNN':0.42,'QDA':0.45,'LDA':0.49,'RDF':0.43},\n",
    "        {'NC': 0.34, 'SVM': 0.10,'KNN':0.47,'QDA':0.48,'LDA':0.39,'RDF':0.51}]\n",
    "index = ['PCA','HOG','HOP']\n",
    "#title = 'Table of model accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>LDA</th>\n",
       "      <th>NC</th>\n",
       "      <th>QDA</th>\n",
       "      <th>RDF</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOG</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOP</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      KNN   LDA    NC   QDA   RDF  SVM\n",
       "PCA  0.32  0.37  0.26  0.19  0.54  0.1\n",
       "HOG  0.42  0.49  0.34  0.45  0.43  0.1\n",
       "HOP  0.47  0.39  0.34  0.48  0.51  0.1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
